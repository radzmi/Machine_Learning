{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wage data introduced\n",
    "All data is in the data directory. This data was downloaded from the ISLR and MASS R packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data into workspace and replicate plots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wage = pd.read_csv('data/wage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wage.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wage.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wage.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at all available plotting styles\n",
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to reshape data to plot correctly\n",
    "df_edu = df_wage.pivot(columns='education', values='wage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing statsmodels library to fit lowess curve through data\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(14,6))\n",
    "df_wage.plot.scatter('age', 'wage', ax=ax[0])\n",
    "lowess = sm.nonparametric.lowess(df_wage['wage'], df_wage['age'], frac=.2)\n",
    "ax[0].plot(lowess[:, 0], lowess[:, 1])\n",
    "\n",
    "df_wage.plot.scatter('year', 'wage', ax=ax[1])\n",
    "year_median = df_wage.groupby('year')['wage'].median()\n",
    "ax[1].plot(year_median)\n",
    "\n",
    "boxplot = df_edu.plot.box(ax=ax[2], rot=45, patch_artist=True)\n",
    "colors = ['lightblue', 'green', 'yellow', 'blue', 'red']\n",
    "for artist, color in zip(boxplot.artists, colors):\n",
    "    artist.set_facecolor(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar plots to those above\n",
    "sns.lmplot(x='age', y='wage', data=df_wage, hue='education')\n",
    "sns.lmplot(x='year', y='wage', data=df_wage, ci=99.99, hue='education');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='education', y='wage', data=df_wage);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_wage[['age', 'year', 'education', 'wage']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = pd.melt(df1, id_vars=['education', 'wage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn_grid = sns.lmplot(x='value', y='wage', col='variable', hue='education', data=df_melt, sharex=False)\n",
    "seaborn_grid.fig.set_figwidth(8)\n",
    "\n",
    "left, bottom, width, height = seaborn_grid.fig.axes[0]._position.bounds\n",
    "left2, bottom2, width2, height2 = seaborn_grid.fig.axes[1]._position.bounds\n",
    "left_diff = left2 - left\n",
    "seaborn_grid.fig.add_axes((left2 + left_diff, bottom, width, height))\n",
    "\n",
    "sns.boxplot(x='education', y='wage', data=df_wage, ax = seaborn_grid.fig.axes[2])\n",
    "ax2 = seaborn_grid.fig.axes[2]\n",
    "ax2.set_yticklabels([])\n",
    "ax2.set_xticklabels(ax2.get_xmajorticklabels(), rotation=30)\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_xlabel('');\n",
    "\n",
    "leg = seaborn_grid.fig.legends[0]\n",
    "leg.set_bbox_to_anchor([0, .1, 1.5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression vs Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smarket = pd.read_csv('data/smarket.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smarket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all lags in one column. Make 'Tidy' Data\n",
    "df_smarket_pivot = pd.melt(df_smarket, \n",
    "                           id_vars='Direction', \n",
    "                           value_vars=['Lag1', 'Lag2', 'Lag3'], \n",
    "                           var_name='Lag Type', \n",
    "                           value_name='Pct Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smarket_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df_smarket_pivot, col=\"Lag Type\", aspect=.6)\n",
    "g = g.map(sns.boxplot, \"Direction\", \"Pct Change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Lag Type\", y=\"Pct Change\", hue=\"Direction\",data=df_smarket_pivot, kind=\"box\", aspect=1.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "No longer interested in prediction - looking to discover underlying similarities in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes = pd.read_csv('data/nci60_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes_transformed = pd.DataFrame(pca.fit_transform(df_genes), columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(df_genes_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes_transformed['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='PC1', y='PC2', data=df_genes_transformed, fit_reg=False, hue='cluster', \n",
    "           scatter_kws={\"marker\": \"D\", \"s\": 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advertising Data\n",
    "The advertising data consists of product sales from 200 markets and their associated tv, radio, and newspaper advertising budgets. What kind of relationship can be seen between advertising budget and sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = pd.read_csv('data/Advertising.csv')\n",
    "df_adv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_new = pd.melt(df_adv, value_vars=['TV', 'Radio', 'Newspaper'], id_vars='Sales', value_name='adv_budget')\n",
    "df_adv_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='adv_budget', y='Sales', data=df_adv_new, hue='variable', fit_reg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(x='adv_budget', y='Sales', data=df_adv_new, col='variable', sharey=False, sharex=False, lowess=True);\n",
    "axes = lm.axes\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.set_xlim(0,)\n",
    "    ax.set_title(lm.col_names[i])\n",
    "    ax.set_xlabel('Advertising Budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data vs Testing Data\n",
    "**Training Data** - Data used to build a prediction model. Should not be used to validate the model.  \n",
    "**Testing Data** - Data used to determine the usefulness of the model. Validates the model. This data is unseen during model building phase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "x = np.linspace(1,13, num_points).reshape(-1, 1)\n",
    "error = np.random.randn(num_points, 1) * num_points\n",
    "f = lambda x: (x - 2) * (x - 6) * (x - 12)\n",
    "\n",
    "y = f(x) + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=10)\n",
    "X = poly.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_nums = np.arange(0, num_points)\n",
    "np.random.shuffle(obs_nums)\n",
    "\n",
    "top_70 = int(num_points * .7)\n",
    "rand_train = np.sort(obs_nums[:top_70])\n",
    "rand_test = np.sort(obs_nums[top_70:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[rand_train]\n",
    "X_test = X[rand_test]\n",
    "y_train = y[rand_train]\n",
    "y_test = y[rand_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train[:, :2], y_train)\n",
    "y_train_2 = linreg.predict(X_train[:, :2])\n",
    "y_test_2 = linreg.predict(X_test[:, :2])\n",
    "\n",
    "linreg.fit(X_train[:, :4], y_train)\n",
    "y_train_4 = linreg.predict(X_train[:, :4])\n",
    "y_test_4 = linreg.predict(X_test[:, :4])\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "y_train_10 = linreg.predict(X_train)\n",
    "y_test_10 = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_train= np.array([np.mean((y_train - y_train_2) ** 2),\n",
    "                        np.mean((y_train - y_train_4) ** 2),\n",
    "                        np.mean((y_train - y_train_10) ** 2)])\n",
    "errors_train = np.column_stack(([2, 4, 10], errors_train))\n",
    "\n",
    "errors_test = np.array([np.mean((y_test - y_test_2) ** 2),\n",
    "                        np.mean((y_test - y_test_4) ** 2),\n",
    "                        np.mean((y_test - y_test_10) ** 2)])\n",
    "errors_test = np.column_stack(([2, 4, 10], errors_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,1], y_train, c='b', label='Train')\n",
    "plt.scatter(X_test[:,1], y_test, c='r', label = 'Test')\n",
    "plt.plot(X_train[:,1], y_train_2, label = '1')\n",
    "plt.plot(X_train[:,1], y_train_4, label = '3')\n",
    "plt.plot(X_train[:,1], y_train_10, label = '10')\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors_train[:, 0], errors_train[:, 1], label = 'Train')\n",
    "plt.plot(errors_test[:, 0], errors_test[:, 1], label = 'Test')\n",
    "plt.hlines(900, 2, 10, label = 'Best', linestyle = '--')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Training and Test MSE\")\n",
    "plt.xlabel('Flexibility')\n",
    "plt.ylabel('MSE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem (advanced)\n",
    "<span style=\"color:green\">Write a function that a takes a list/array of how many parameters to fit a linear regression model for the above data and outputs the two plots above.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "3a. Hand-picked points to show the 5 curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.array([6, 4, 2, 1, .5, .1])\n",
    "variance = bias[::-1]\n",
    "training_error = bias * 1.1\n",
    "test_error = np.array([7, 5, 2, 2, 5, 7])\n",
    "irreducible_error = np.ones(6) * 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame({'bias': bias,\n",
    "              'variance':variance,\n",
    "             'training_error': training_error,\n",
    "             'test_error':test_error,\n",
    "             'irreducible_error': irreducible_error})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.plot()\n",
    "plt.xlabel('Complexity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = pd.DataFrame({'x1': [0, 2, 0, 0, -1, 1], 'x2':[3, 0, 1, 1, 0, 1], 'x3':[0, 0, 3, 2, 1, 1], \n",
    "                     'y':['R', 'R', 'R', 'G', 'G', 'R']})\n",
    "df_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART a\n",
    "# Get x1, x2, x3 from the above dataframe. Subtract (0, 0, 0) from it and square each dimension\n",
    "dist = (df_7.values[:, :3] - np.array([0, 0, 0])) ** 2\n",
    "\n",
    "# Sum across the rows and make sure the type is float\n",
    "summed_distance = dist.sum(axis=1).astype('float')\n",
    "\n",
    "# Take square root to get euclidean distance\n",
    "euclidean_dist = np.sqrt(summed_distance)\n",
    "euclidean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_college = pd.read_csv('data/college.csv', index_col=0)\n",
    "df_college.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i\n",
    "df_college.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii\n",
    "sns.pairplot(df_college.iloc[:, :10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iii\n",
    "sns.boxplot('Private', 'Outstate', data=df_college);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv\n",
    "# Next line produces No/Yes categories based on a boolean(0/1) and saves it as a DataFrame column\n",
    "df_college['Elite'] = pd.Categorical(np.where(df_college['Top10perc'] > 50, 'Yes', 'No'))\n",
    "print(df_college['Elite'].value_counts())\n",
    "sns.boxplot('Elite', 'Outstate', data=df_college);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v\n",
    "fig , ax = plt.subplots(2, 2, figsize=(12,8))\n",
    "ax[0, 0].hist(df_college['Accept'] / df_college['Apps'] , bins=5)\n",
    "ax[0, 0].set_title('Percentage Accepted')\n",
    "\n",
    "ax[0, 1].hist(df_college['Accept'] / df_college['Apps'] , bins=10)\n",
    "ax[0, 1].set_title('Percentage Accepted')\n",
    "\n",
    "ax[1, 0].hist(df_college['Accept'] / df_college['Apps'] , bins=15)\n",
    "ax[1, 0].set_title('Percentage Accepted')\n",
    "\n",
    "ax[1, 1].hist(df_college['Accept'] / df_college['Apps'] , bins=20)\n",
    "ax[1, 1].set_title('Percentage Accepted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi\n",
    "# Acceptance rate and Graduation rate are negatively correlated\n",
    "df_college['Accept_Rate'] = df_college['Accept'] / df_college['Apps']\n",
    "sns.lmplot('Accept_Rate', 'Grad.Rate', data=df_college);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto = pd.read_csv('data/auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Quantitative vs Qualitative Predictors  \n",
    "Quantitative - mpg, cylinders, displacement, horsepower, weight, acceleration  \n",
    "Qualitative - year, origin, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b and c - get the range and std of each quantitative predictor\n",
    "df_auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d\n",
    "pd.concat((df_auto.iloc[:10], df_auto.iloc[85:])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e\n",
    "# Horsepower and displacement have a very strong postive linear relationship. Horsepower and mpg \n",
    "# have a strong negative relationship\n",
    "sns.pairplot(df_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Looking at the pair plots above, mpg seems to have some relationship with just about all the other predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston = pd.read_csv('data/boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame contains the following columns:\n",
    "\n",
    "crim\n",
    "per capita crime rate by town.\n",
    "\n",
    "zn\n",
    "proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "indus\n",
    "proportion of non-retail business acres per town.\n",
    "\n",
    "chas\n",
    "Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "nox\n",
    "nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "rm\n",
    "average number of rooms per dwelling.\n",
    "\n",
    "age\n",
    "proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "dis\n",
    "weighted mean of distances to five Boston employment centres.\n",
    "\n",
    "rad\n",
    "index of accessibility to radial highways.\n",
    "\n",
    "tax\n",
    "full-value property-tax rate per \\$10,000.\n",
    "\n",
    "ptratio\n",
    "pupil-teacher ratio by town.\n",
    "\n",
    "black\n",
    "1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "\n",
    "lstat\n",
    "lower status of the population (percent).\n",
    "\n",
    "medv\n",
    "median value of owner-occupied homes in \\$1000s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pair plot is too large. Lets plot correlations and \n",
    "df_boston.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) There are no very strong relationships (> .9) with crime. The highest two are **rad**, **tax** and **lstat**. Crime is correlated with density of population (from what I've read before) so rad might be representative of how dense the population is if you are close to highways. Tax rates are generally higher the closer you are to a city center so higher tax rates might imply denser populations. And lower status (lstat) makes sense since more crime is committed by those less well off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Below are the towns that have a max for each of the predictors. Seems there are some limitation in the data such that 132 towns have exactly 24 as a value for rad and 121 towns have exactly 396.9 as a value for black. Crime also seems to be strangely distributed with nearly all values hovering around 0 and a few serveral orders of magnitude greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston.loc[df_boston.idxmax().unique()].style.highlight_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_boston['rad'] == 24).sum(), (df_boston['black'] == 396.9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_boston['crim']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e\n",
    "df_boston['chas'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\n",
    "df_boston['ptratio'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g\n",
    "# rad and black are both those suspicious maximum values and crim is a ridiculous outlier. More evidence\n",
    "# of bad data\n",
    "df_boston.loc[df_boston['medv'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h\n",
    "(df_boston['rm'] > 7).sum(), (df_boston['rm'] > 8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'More than 8 rooms': df_boston[df_boston['rm'] > 8].describe().loc['50%'], \n",
    "              '8 or less rooms' : df_boston[df_boston['rm'] <= 8].describe().loc['50%']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the predictors are the similar in both groups except crime and median value of homes - both about double for more than 8 rooms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
